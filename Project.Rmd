

```{r}
library(nnet)
library(class)
library(rpart)
library(arm)
library(dplyr)
library(ggplot2)
library(partykit)
library(data.table)
library(randomForest)
library(tibble)
library(tidyverse)
library(e1071)
library(gmodels)
library(C50)
library(tictoc)
library(caret)

```

loan_amnt to know how much was asked for
funded_amnt to know how much was approved for
installment to know the installment rate
term to know the term of the loan
home_ownership to know home ownership status
annual_inc to know the annual income
purpose to know the purpose of the loan
```{r}

LC <- readRDS("LCLH.rds")

LC <- data.frame(    loan_amnt=LC$loan_amnt, 
                      funded_amnt=LC$funded_amnt,
                      installment=LC$installment,
                      term=LC$term, 
                      home_ownership=LC$home_ownership,
                      annual_inc=LC$annual_inc, 
                      purpose=LC$purpose)

LC <- droplevels(LC)

LC = na.omit(LC, cols=c("loan_amnt","funded_amnt", "installment", "term", "home_ownership", "annual_inc", "purpose"))

LC <- droplevels(LC)

unique(LC$term)
```

```{r}

colnames <- colnames(LC)
colnames
```

```{r}

nrows <- nrow(LC)
nrows

ncols <- ncol(LC)
ncols

```

```{r}


set.seed(1) 

n <- nrow(LC) 
test_idx <- sample.int(n, size = round(0.25 * n)) 
train <- LC[-test_idx, ] 
nrow(train)

test <- LC[test_idx, ]
nrow(test)

```

#Logistic Regression
#train
```{r}
train$term <- as.factor(train$term)


model <- bayesglm(term ~ .,family=binomial,data=train)
model

summary(model)
```

#test
```{r}
test$term <- as.factor(test$term)


model <- bayesglm(term ~ .,family=binomial,data=test)
model

summary(model)
```

##Decision Tree


#train
```{r}
form <- as.formula(term ~ loan_amnt + funded_amnt + installment + home_ownership + annual_inc + purpose) 

mod_tree <- rpart(form, data = train)
mod_tree
```

```{r}
rpart(term ~ loan_amnt, data = train) 

split <- 9987.5 
train.DT <- train %>% mutate(hi_loan_amnt = loan_amnt >= split)

ggplot(data = train.DT, aes(x = loan_amnt, y = term)) + geom_count(aes(color = hi_loan_amnt),
position = position_jitter(width = 0, height = 0.1), alpha = 0.5) + 
  geom_vline(xintercept = split, color = "dodgerblue", lty = 2) 

```

```{r}
plot(as.party(mod_tree))

```

```{r}
printcp(mod_tree)
plotcp(mod_tree)

```

```{r}
train.C <- train %>% mutate(term_dtree = predict(mod_tree, type = "class"))
confusion <- CrossTable(train.C$term_dtree, train.C$term, expected = FALSE, prop.r = FALSE, prop.c = FALSE, prop.chisq = FALSE)

confusion$t

sum(diag(confusion$t)) / nrow(train.C)


```

#test
```{r}
form <- as.formula(term ~ loan_amnt + funded_amnt + installment + home_ownership + annual_inc + purpose) 

mod_tree <- rpart(form, data = test)
mod_tree
```

```{r}
rpart(term ~ loan_amnt, data = test) 

split <- 9987.5 
test.DT <- test %>% mutate(hi_loan_amnt = loan_amnt >= split)

ggplot(data = test.DT, aes(x = loan_amnt, y = term)) + geom_count(aes(color = hi_loan_amnt),
position = position_jitter(width = 0, height = 0.1), alpha = 0.5) + 
  geom_vline(xintercept = split, color = "dodgerblue", lty = 2) 

```

```{r}
plot(as.party(mod_tree))

```

```{r}
printcp(mod_tree)
plotcp(mod_tree)

```

```{r}
test.C <- test %>% mutate(term_dtree = predict(mod_tree, type = "class"))
confusion <- CrossTable(test.C$term_dtree, test.C$term, expected = FALSE, prop.r = FALSE, prop.c = FALSE, prop.chisq = FALSE)

confusion$t

sum(diag(confusion$t)) / nrow(test.C)


```

##C5.0
#train
```{r}

tic()
m_c50_bst <- C5.0(term ~ ., data = train, trials = 50)
toc()

term_pred <- predict(m_c50_bst, train)
confusionMatrix(data=term_pred, train$term)
```

#train
```{r}

tic()
m_c50_bst <- C5.0(term ~ ., data = test, trials = 50)
toc()

term_predt <- predict(m_c50_bst, test)
confusionMatrix(data=term_predt, test$term)
```


##random forest
#train
```{r}


mod_forest <- randomForest(form, data = train, ntree = 50, mtry = 3) 
mod_forest

sum(diag(mod_forest$confusion)) / nrow(train)


```

```{r}
importance(mod_forest) %>%
as.data.frame() %>% 
rownames_to_column() %>% 
arrange(desc(MeanDecreaseGini))
```

#test
```{r}


mod_forest <- randomForest(form, data = test, ntree = 50, mtry = 3) 
mod_forest

sum(diag(mod_forest$confusion)) / nrow(test)


```

```{r}
importance(mod_forest) %>%
as.data.frame() %>% 
rownames_to_column() %>% 
arrange(desc(MeanDecreaseGini))
```

##Naive Bayes
#train
```{r}

form <- as.formula(term ~ loan_amnt + funded_amnt + installment + annual_inc) 

 
mod_nb <- naiveBayes(form, data = train) 
term_nb <- predict(mod_nb, newdata = train) 

confusion <- CrossTable(term_nb, train$term, expected = FALSE, prop.r = FALSE, prop.c = FALSE, prop.chisq = FALSE)

confusion$t

sum(diag(confusion$t)) / nrow(train)

```

#test
```{r}

form <- as.formula(term ~ loan_amnt + funded_amnt + installment + annual_inc) 

 
mod_nb <- naiveBayes(form, data = test) 
term_nbt <- predict(mod_nb, newdata = test) 

confusion <- CrossTable(term_nbt, test$term, expected = FALSE, prop.r = FALSE, prop.c = FALSE, prop.chisq = FALSE)

confusion$t

sum(diag(confusion$t)) / nrow(test)

```

##Neural Network
#train
```{r}

 mod_nn <- nnet(form, data = train, size = 3)


term_nn <- predict(mod_nn, newdata = train, type = "class") 
confusion <- CrossTable(term_nn, train$term, expected = FALSE, prop.r = FALSE, prop.c = FALSE, prop.chisq = FALSE) 
confusion$t


sum(diag(confusion$t)) / nrow(train)
```

#test
```{r}

 mod_nn <- nnet(form, data = test, size = 3)


term_nnt <- predict(mod_nn, newdata = test, type = "class") 
confusion <- CrossTable(term_nnt, test$term, expected = FALSE, prop.r = FALSE, prop.c = FALSE, prop.chisq = FALSE) 
confusion$t


sum(diag(confusion$t)) / nrow(test)
```

##Ensemble Method
#train
```{r}
term_ensemble <- ifelse((term_pred == " 60 months") + 
                            (term_nb == " 60 months") +
                            (term_nn == " 60 months") >= 2, " 60 months", " 36 months") 

confusion <- CrossTable(term_ensemble, train$term, expected = FALSE, prop.r = FALSE, prop.c = FALSE, prop.chisq = FALSE)
confusion$t

sum(diag(confusion$t)) / nrow(train) 

```

#test
```{r}
term_ensemble <- ifelse((term_predt == " 60 months") + 
                            (term_nbt == " 60 months") +
                            (term_nnt == " 60 months") >= 2, " 60 months", " 36 months") 

confusion <- CrossTable(term_ensemble, test$term, expected = FALSE, prop.r = FALSE, prop.c = FALSE, prop.chisq = FALSE)
confusion$t

sum(diag(confusion$t)) / nrow(test) 

```


C5.0, neural network and randomForest were really close in there model accuracy but C5.0 was a better model and an ensemble of C5.0, Naive Bayes and neural network were performed on the model, making it an even better model since it has even more classification. Based on the logistic model there was no room to reduce it by reducing the number of variables. (knn was to taxing on the computer to include into the report)

All models were relatively similar when it comes to the train and test and the ensemble did better in test. It was a large data set, to take into account.
